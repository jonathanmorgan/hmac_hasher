{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Hashing-PII-columns-in-data\" data-toc-modified-id=\"Hashing-PII-columns-in-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Hashing PII columns in data</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup---Imports\" data-toc-modified-id=\"Setup---Imports-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Setup - Imports</a></span></li><li><span><a href=\"#Setup---Files-and-Directories\" data-toc-modified-id=\"Setup---Files-and-Directories-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Setup - Files and Directories</a></span></li><li><span><a href=\"#Setup---Initialize-HMACHasher-with-salts\" data-toc-modified-id=\"Setup---Initialize-HMACHasher-with-salts-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Setup - Initialize HMACHasher with salts</a></span><ul class=\"toc-item\"><li><span><a href=\"#name-HMACHasher\" data-toc-modified-id=\"name-HMACHasher-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>name HMACHasher</a></span></li><li><span><a href=\"#SSN-HMACHasher\" data-toc-modified-id=\"SSN-HMACHasher-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>SSN HMACHasher</a></span></li></ul></li><li><span><a href=\"#Setup---Functions\" data-toc-modified-id=\"Setup---Functions-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Setup - Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Functions---hash-functions\" data-toc-modified-id=\"Functions---hash-functions-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Functions - hash functions</a></span></li></ul></li></ul></li><li><span><a href=\"#Hash-data\" data-toc-modified-id=\"Hash-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Hash data</a></span></li><li><span><a href=\"#Evaluate\" data-toc-modified-id=\"Evaluate-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Evaluate</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing PII columns in data\n",
    "\n",
    "This example notebook hashes the Name fields and SSN in a sample data file.\n",
    "\n",
    "In this example a set of data files are broken into multiple files, one file per quarter, one row per unit of interest.  This code reads directly from the original files row by row, hashing column values for each row and building an output row with same number of columns, but hashed values where desired, then writing each row to an output file.\n",
    "\n",
    "Logic overiew - for each row in CSV file:\n",
    "- reads row from original CSV file into a row value list.\n",
    "- makes a copy of the row value list, for output.\n",
    "- pulls in the fields to hash, hashes them, then replaces existing values in output list with hashed values.\n",
    "- writes hashed row to output CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Imports\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-15T18:13:58.472721Z",
     "start_time": "2018-02-15T18:13:58.465124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports imported at 2018-02-15 13:13:58.468827\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import csv\n",
    "import datetime\n",
    "import glob\n",
    "import hashlib\n",
    "import six\n",
    "import uuid\n",
    "\n",
    "print( \"Imports imported at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Files and Directories\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-15T18:13:59.819691Z",
     "start_time": "2018-02-15T18:13:59.809496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jonathanmorgan/Google Drive/work/data_curation/code_to_share'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-15T18:14:00.425479Z",
     "start_time": "2018-02-15T18:14:00.415940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories configured at 2018-02-15 13:14:00.422723\n"
     ]
    }
   ],
   "source": [
    "# work directories\n",
    "#root_directory = \"workspace\"\n",
    "#configuration_directory = \"configuration\"\n",
    "#work_directory = root_directory + \"work\"\n",
    "#data_directory = root_directory + \"ingest\"\n",
    "#source_directory = data_directory + \"original_data\"\n",
    "#output_directory = root_directory + \"hashed_output\"\n",
    "\n",
    "# can get fancy, for example, all are current directory.\n",
    "root_directory = \".\"\n",
    "configuration_directory = root_directory + \"/examples\"\n",
    "work_directory = \".\"\n",
    "data_directory = root_directory + \"/examples\"\n",
    "source_directory = data_directory\n",
    "output_directory = \".\"\n",
    "\n",
    "# variable names used in the code below.\n",
    "input_file_directory_path = source_directory\n",
    "output_file_directory_path = output_directory\n",
    "\n",
    "print( \"Directories configured at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Initialize HMACHasher with salts\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "We have a shared HMAC passphrase we will use for hashing.  We can just set the object up here, then use map to call it on each column we need to hash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-15T18:14:01.796101Z",
     "start_time": "2018-02-15T18:14:01.792489Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first, load the HMACHasher class.\n",
    "hmac_hasher_folder_path = work_directory + \"/hmac_hasher\"\n",
    "hmac_hasher_class_file_path = hmac_hasher_folder_path + \"/hmac_hasher.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the \"%run\" command to run the Python file that defines the HMACHasher class and load the class into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-15T18:14:02.977216Z",
     "start_time": "2018-02-15T18:14:02.969646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMACHasher class imported from ./hmac_hasher/hmac_hasher.py at 2018-02-15 13:14:02.974234\n"
     ]
    }
   ],
   "source": [
    "%run $hmac_hasher_class_file_path\n",
    "\n",
    "print( \"HMACHasher class imported from {} at {}\".format( hmac_hasher_class_file_path, str( datetime.datetime.now() ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### name HMACHasher\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-15T18:14:04.497515Z",
     "start_time": "2018-02-15T18:14:04.480753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Loading configuration from: ./examples/name_hashing_configuration.ini\n",
      "\n",
      "Config loaded from path ./examples/name_hashing_configuration.ini at 2018-02-15 13:14:04.494828\n",
      "HMACHasher instances created at 2018-02-15 13:14:04.495056\n"
     ]
    }
   ],
   "source": [
    "# make instance of the HMACHasher for names\n",
    "my_name_hasher = HMACHasher()\n",
    "\n",
    "# load the passphrase/salt from the configuration file\n",
    "hmac_hasher_ini_file_path = configuration_directory + \"/name_hashing_configuration.ini\"\n",
    "\n",
    "# store configuration file path in HMACHasher, then load config.\n",
    "my_name_hasher.configuration_ini_file_path = hmac_hasher_ini_file_path\n",
    "config_load_messages = my_name_hasher.load_configuration_from_ini_file()\n",
    "\n",
    "# errors?\n",
    "if ( len( config_load_messages ) > 0 ):\n",
    "\n",
    "    # errors.\n",
    "    for error_message in config_load_messages:\n",
    "        \n",
    "        print( \"- \" + str( error_message ) )\n",
    "        \n",
    "    #-- END loop over errors. --#\n",
    "\n",
    "else:\n",
    "    \n",
    "    print( \"Config loaded from path \" + str( hmac_hasher_ini_file_path ) + \" at \" + str( datetime.datetime.now() ) )\n",
    "    \n",
    "#-- END check for errors loading configuration. --#\n",
    "\n",
    "print( \"HMACHasher instances created at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-15T18:14:05.577809Z",
     "start_time": "2018-02-15T18:14:05.569818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM Exculpatory TO 2990abf7de79499d1869bef3d1af456c0f24abfb85e7348a59d99ce6a8962ae5\n",
      "Equal to expected?: True\n"
     ]
    }
   ],
   "source": [
    "# test hashing a value.\n",
    "expected_value = \"2990abf7de79499d1869bef3d1af456c0f24abfb85e7348a59d99ce6a8962ae5\"\n",
    "\n",
    "# with other than the example secret, on first run, this will not match.  To test:\n",
    "# - Copy value from first run into expected_value, above.\n",
    "# - stop kernel and clear output.\n",
    "# - run all cells again.\n",
    "\n",
    "test_value = \"Exculpatory\"\n",
    "test_hash = \"\"\n",
    "test_hash = my_name_hasher.hash_value( test_value )\n",
    "print( \"FROM \" + str( test_value ) + \" TO \" + str( test_hash ) )\n",
    "print( \"Equal to expected?: \" + str( expected_value == test_hash ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSN HMACHasher\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-15T18:14:07.090274Z",
     "start_time": "2018-02-15T18:14:07.073751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Loading configuration from: ./examples/ssn_hashing_configuration.ini\n",
      "\n",
      "Config loaded from path ./examples/ssn_hashing_configuration.ini at 2018-02-15 13:14:07.086858\n",
      "HMACHasher instances created at 2018-02-15 13:14:07.086930\n"
     ]
    }
   ],
   "source": [
    "# make instance of the HMACHasher for SSN\n",
    "my_ssn_hasher = HMACHasher()\n",
    "\n",
    "# load the passphrase/salt from the configuration file\n",
    "hmac_hasher_ini_file_path = configuration_directory + \"/ssn_hashing_configuration.ini\"\n",
    "\n",
    "# store configuration file path in HMACHasher, then load config.\n",
    "my_ssn_hasher.configuration_ini_file_path = hmac_hasher_ini_file_path\n",
    "config_load_messages = my_ssn_hasher.load_configuration_from_ini_file()\n",
    "\n",
    "# errors?\n",
    "if ( len( config_load_messages ) > 0 ):\n",
    "\n",
    "    # errors.\n",
    "    for error_message in config_load_messages:\n",
    "        \n",
    "        print( \"- \" + str( error_message ) )\n",
    "        \n",
    "    #-- END loop over errors. --#\n",
    "\n",
    "else:\n",
    "    \n",
    "    print( \"Config loaded from path \" + str( hmac_hasher_ini_file_path ) + \" at \" + str( datetime.datetime.now() ) )\n",
    "    \n",
    "#-- END check for errors loading configuration. --#\n",
    "\n",
    "print( \"HMACHasher instances created at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-15T18:14:08.828439Z",
     "start_time": "2018-02-15T18:14:08.818316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM Exculpatory TO f20444b7c321517ac2b4c73af8de3bc888ddee0980d52cf5c3ec9f348c670192\n",
      "Equal to expected?: True\n"
     ]
    }
   ],
   "source": [
    "# test hashing a value.\n",
    "expected_value = \"f20444b7c321517ac2b4c73af8de3bc888ddee0980d52cf5c3ec9f348c670192\"\n",
    "\n",
    "# with other than the example secret, on first run, this will not match.  To test:\n",
    "# - Copy value from first run into expected_value, above.\n",
    "# - stop kernel and clear output.\n",
    "# - run all cells again.\n",
    "\n",
    "test_value = \"Exculpatory\"\n",
    "test_hash = \"\"\n",
    "test_hash = my_ssn_hasher.hash_value( test_value )\n",
    "print( \"FROM \" + str( test_value ) + \" TO \" + str( test_hash ) )\n",
    "print( \"Equal to expected?: \" + str( expected_value == test_hash ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Functions\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions - hash functions\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-15T18:14:17.520201Z",
     "start_time": "2018-02-15T18:14:17.500175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function hash_ssn() declared at 2018-02-15 13:14:17.516613\n",
      "Function hash_name() declared at 2018-02-15 13:14:17.516953\n"
     ]
    }
   ],
   "source": [
    "def hash_ssn( value_IN, hasher_IN = my_ssn_hasher ):\n",
    "    \n",
    "    # return reference\n",
    "    hash_OUT = \"\"\n",
    "    \n",
    "    # hash using SSN method:\n",
    "    # - removes punctuation\n",
    "    # - replaces multiple spaces with a single space\n",
    "    # - strips white space from ends\n",
    "    hash_OUT = hasher_IN.hash_ssn_value( value_IN )\n",
    "    \n",
    "    return hash_OUT\n",
    "\n",
    "#-- END function hash_ssn() --#\n",
    "\n",
    "print( \"Function hash_ssn() declared at \" + str( datetime.datetime.now() ) )\n",
    "\n",
    "    \n",
    "def hash_name( value_IN, hasher_IN = my_name_hasher ):\n",
    "    \n",
    "    # return reference\n",
    "    hash_OUT = \"\" \n",
    "     \n",
    "    # hash using name method to standardize:\n",
    "    # - converts to upper case\n",
    "    # - removes punctuation\n",
    "    # - replaces multiple spaces with a single space\n",
    "    # - strips white space from ends\n",
    "    hash_OUT = hasher_IN.hash_name_value( value_IN )\n",
    "    \n",
    "    return hash_OUT\n",
    "\n",
    "#-- END function hash_name() --#\n",
    "\n",
    "print( \"Function hash_name() declared at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hash data\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-15T18:14:19.960676Z",
     "start_time": "2018-02-15T18:14:19.580924Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for files in ./examples\n",
      "File list: ['./examples/Fake_Data_Test_001.csv', './examples/Fake_Data_Test_002.csv']\n",
      "--> Current file: Fake_Data_Test_001.csv @ 2018-02-15 13:14:19.956104\n",
      "--> Current file: Fake_Data_Test_002.csv @ 2018-02-15 13:14:19.957365\n",
      "All files processed at 2018-02-15 13:14:19.958381\n"
     ]
    }
   ],
   "source": [
    "# ==> example data\n",
    "\n",
    "# declare variables - loop over files\n",
    "file_list = []\n",
    "file_path = \"\"\n",
    "path_part_list = []\n",
    "file_name = \"\"\n",
    "temp_file_name = \"\"\n",
    "file_year = \"\"\n",
    "file_quarter = \"\"\n",
    "\n",
    "# file details - indexes start at 0.\n",
    "index_ssn = 1\n",
    "index_first_name = 2\n",
    "index_middle_name = 3\n",
    "index_last_name = 4\n",
    "\n",
    "# declare variables - process each file\n",
    "path_separator = \"/\"\n",
    "input_file = \"\"\n",
    "input_file_encoding = \"utf-8\"\n",
    "has_header_row = True\n",
    "output_file = \"\"\n",
    "line_counter = -1\n",
    "hash_output_file = None\n",
    "to_hash_csv_file = None\n",
    "input_csv_reader = None\n",
    "output_csv_writer = None\n",
    "current_record = None\n",
    "\n",
    "# values from record\n",
    "ssn_value = \"\"\n",
    "first_name_value = \"\"\n",
    "middle_name_value = \"\"\n",
    "last_name_value = \"\"\n",
    "hashed_ssn = \"\"\n",
    "hashed_first_name = \"\"\n",
    "hashed_middle_name = \"\"\n",
    "hashed_last_name = \"\"\n",
    "row_value_list = []\n",
    "\n",
    "# first get list of *.csv files in directory.\n",
    "print( \"Looking for files in {}\".format( input_file_directory_path ) )\n",
    "file_list = glob.glob( input_file_directory_path + \"/*.csv\" )\n",
    "print( \"File list: \" + str( file_list ) )\n",
    "\n",
    "for file_path in file_list:\n",
    "    \n",
    "    # Parse out the file name.  Name pattern: il_wage_2012q1.csv\n",
    "    path_part_list = file_path.split( path_separator )\n",
    "    file_name = path_part_list[ -1 ]\n",
    "    \n",
    "    print( \"--> Current file: {} @ {}\".format( str( file_name ), str( datetime.datetime.now() ) ) )\n",
    "\n",
    "    # initialize\n",
    "    line_counter = 0\n",
    "    input_file = file_path\n",
    "    output_file = output_file_directory_path + \"/hashed-\" + file_name\n",
    "\n",
    "    # open the output file for writing.\n",
    "    with open( output_file, \"w\" ) as hash_output_file:\n",
    "\n",
    "        # init CSV writer.\n",
    "        output_csv_writer = csv.writer( hash_output_file, delimiter = \",\" )\n",
    "\n",
    "        # open the input file for reading\n",
    "        with open( input_file, encoding = input_file_encoding ) as to_hash_csv_file:\n",
    "\n",
    "            # get a CSV reader\n",
    "            input_csv_reader = csv.reader( to_hash_csv_file )\n",
    "\n",
    "            # output header row?\n",
    "            if ( has_header_row == True ):\n",
    "                \n",
    "                # yes - output first row as is.\n",
    "                row_value_list = input_csv_reader.__next__()\n",
    "                output_csv_writer.writerow( row_value_list )\n",
    "                \n",
    "            #-- END check to see if header row --#\n",
    "\n",
    "            # loop over records\n",
    "            for current_record in input_csv_reader:\n",
    "                \n",
    "                # initialize values\n",
    "                ein_value = \"\"\n",
    "                business_name_value = \"\"\n",
    "                business_name_2_value = \"\"\n",
    "                hashed_ein = \"\"\n",
    "                hashed_business_name = \"\"\n",
    "                hashed_business_name_2 = \"\"\n",
    "\n",
    "                # initialize output list with copy of input list\n",
    "                row_value_list = copy.copy( current_record )\n",
    "\n",
    "                # increment line counter\n",
    "                line_counter += 1\n",
    "\n",
    "                # get values (check if positions are correct)\n",
    "                \n",
    "                # got an SSN list index?\n",
    "                if ( index_ssn is not None ):\n",
    "\n",
    "                    # we have an index.  Get value...\n",
    "                    ssn_value = current_record[ index_ssn ]\n",
    "                    \n",
    "                    # ...hash...\n",
    "                    hashed_ssn = hash_ssn( ssn_value )\n",
    "                    \n",
    "                    # ...and store in output row.\n",
    "                    row_value_list[ index_ssn ] = hashed_ssn\n",
    "                    \n",
    "                #-- END check to see if SSN index. --#\n",
    "\n",
    "                # got a last name list index?\n",
    "                if ( index_last_name is not None ):\n",
    "\n",
    "                    # we have an index.  Get value...\n",
    "                    last_name_value = current_record[ index_last_name ]\n",
    "                    \n",
    "                    # ...hash...\n",
    "                    hashed_last_name = hash_name( last_name_value )\n",
    "                    \n",
    "                    # ...and store in output row.\n",
    "                    row_value_list[ index_last_name ] = hashed_last_name\n",
    "                    \n",
    "                #-- END check to see if last name index. --#\n",
    "\n",
    "                # got a first name list index?\n",
    "                if ( index_first_name is not None ):\n",
    "\n",
    "                    # we have an index.  Get value...\n",
    "                    first_name_value = current_record[ index_first_name ]\n",
    "                    \n",
    "                    # ...hash...\n",
    "                    hashed_first_name = hash_name( first_name_value )\n",
    "                    \n",
    "                    # ...and store in output row.\n",
    "                    row_value_list[ index_first_name ] = hashed_first_name\n",
    "                    \n",
    "                #-- END check to see if first name index. --#\n",
    "                \n",
    "                # got a middle name list index?\n",
    "                if ( index_middle_name is not None ):\n",
    "\n",
    "                    # we have an index.  Get value...\n",
    "                    middle_name_value = current_record[ index_middle_name ]\n",
    "                    \n",
    "                    # ...hash...\n",
    "                    hashed_middle_name = hash_name( middle_name_value )\n",
    "                    \n",
    "                    # ...and store in output row.\n",
    "                    row_value_list[ index_middle_name ] = hashed_middle_name\n",
    "                    \n",
    "                #-- END check to see if middle name index. --#\n",
    "                \n",
    "                # write to output file.\n",
    "                output_csv_writer.writerow( row_value_list )\n",
    "\n",
    "                if ( ( line_counter % 100000 ) == 0 ):\n",
    "                    print( \"- Hashed \" + str( line_counter ) + \" lines at \" + str( datetime.datetime.now() ) )\n",
    "                #-- END check to see if we've done 1000 records. --#\n",
    "\n",
    "            #-- END loop over input lines.\n",
    "\n",
    "        #-- END with ... to_hash_csv_file --#\n",
    "\n",
    "    #-- END with ... hash_output_file --#    \n",
    "\n",
    "#-- END loop over file list --#\n",
    "\n",
    "print( \"All files processed at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluate\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Once the cell above has completed, you should now have two files, `hashed-Fake_Data_Test_001.csv` and `hashed-Fake_Data_Test_002.csv` in your output folder (by default, the same directory as this notebook).  The two input files are identical, so the resulting output should also be identical."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
