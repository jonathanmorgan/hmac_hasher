{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Hashing-PII-columns-in-data\" data-toc-modified-id=\"Hashing-PII-columns-in-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Hashing PII columns in data</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup---Imports\" data-toc-modified-id=\"Setup---Imports-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Setup - Imports</a></span></li><li><span><a href=\"#Setup---Files-and-Directories\" data-toc-modified-id=\"Setup---Files-and-Directories-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Setup - Files and Directories</a></span></li><li><span><a href=\"#Setup---Initialize-HMACHasher-with-salts\" data-toc-modified-id=\"Setup---Initialize-HMACHasher-with-salts-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Setup - Initialize HMACHasher with salts</a></span><ul class=\"toc-item\"><li><span><a href=\"#shared-HMACHasher\" data-toc-modified-id=\"shared-HMACHasher-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>shared HMACHasher</a></span></li></ul></li><li><span><a href=\"#Setup---Functions\" data-toc-modified-id=\"Setup---Functions-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Setup - Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Functions---hash-functions\" data-toc-modified-id=\"Functions---hash-functions-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Functions - hash functions</a></span></li></ul></li></ul></li><li><span><a href=\"#Hash-data\" data-toc-modified-id=\"Hash-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Hash data</a></span><ul class=\"toc-item\"><li><span><a href=\"#function-parse_fixed_width_record\" data-toc-modified-id=\"function-parse_fixed_width_record-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>function parse_fixed_width_record</a></span></li><li><span><a href=\"#fixed-width-field-spec\" data-toc-modified-id=\"fixed-width-field-spec-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>fixed-width field spec</a></span></li><li><span><a href=\"#hashing-spec\" data-toc-modified-id=\"hashing-spec-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>hashing spec</a></span></li><li><span><a href=\"#hash!\" data-toc-modified-id=\"hash!-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>hash!</a></span></li></ul></li><li><span><a href=\"#Evaluate\" data-toc-modified-id=\"Evaluate-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Evaluate</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing PII columns in data\n",
    "\n",
    "This example notebook hashes the Name fields and SSN in a sample data file.\n",
    "\n",
    "In this example a set of data files are broken into multiple files, one file per quarter, one row per unit of interest.  This code reads directly from the original files row by row, hashing column values for each row and building an output row with same number of columns, but hashed values where desired, then writing each row to an output file.\n",
    "\n",
    "Logic overiew - for each row in fixed-width file:\n",
    "\n",
    "- reads row from original fixed-width CSV file into a row value list.\n",
    "- makes a copy of the row value list, for output.\n",
    "- pulls in the fields to hash, hashes them, then replaces existing values in output list with hashed values.\n",
    "- writes hashed row to output CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Imports\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "import datetime\n",
    "import glob\n",
    "import hashlib\n",
    "import six\n",
    "import uuid\n",
    "\n",
    "print( \"Imports imported at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Files and Directories\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work directories\n",
    "#root_directory = \"workspace\"\n",
    "#configuration_directory = \"configuration\"\n",
    "#work_directory = root_directory + \"work\"\n",
    "#data_directory = root_directory + \"ingest\"\n",
    "#source_directory = data_directory + \"original_data\"\n",
    "#output_directory = root_directory + \"hashed_output\"\n",
    "\n",
    "# can get fancy, for example, all are current directory.\n",
    "root_directory = \".\"\n",
    "configuration_directory = root_directory + \"/examples\"\n",
    "work_directory = \".\" # needs to be a directory that has the hmac_hasher folder that sits alongside this file in the repository inside of it.\n",
    "data_directory = root_directory + \"/examples\"\n",
    "source_directory = data_directory\n",
    "output_directory = \".\"\n",
    "\n",
    "# variable names used in the code below.\n",
    "input_file_directory_path = source_directory\n",
    "output_file_directory_path = output_directory\n",
    "\n",
    "print( \"Directories configured at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Initialize HMACHasher with salts\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "We have a shared HMAC passphrase we will use for hashing.  We can just set the object up here, then use map to call it on each column we need to hash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, load the HMACHasher class.\n",
    "hmac_hasher_folder_path = work_directory + \"/hmac_hasher\"\n",
    "hmac_hasher_class_file_path = hmac_hasher_folder_path + \"/hmac_hasher.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the \"%run\" command to run the Python file that defines the HMACHasher class and load the class into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run $hmac_hasher_class_file_path\n",
    "\n",
    "print( \"HMACHasher class imported from {} at {}\".format( hmac_hasher_class_file_path, str( datetime.datetime.now() ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shared HMACHasher\n",
    "\n",
    "Sometimes you will have a secret per field or field type.  In this case, we are using a single secret for all fields, so only need one configuration and one hasher.\n",
    "\n",
    "The secret is stored in a configuration INI file, so it can persist but not be explicitly present in code files.\n",
    "\n",
    "The minimal configuration needed for this is a \"[secret]\" section that contains a \"passphrase\".  An example:\n",
    "\n",
    "    [secret]\n",
    "\n",
    "    passphrase=fakedata\n",
    "\n",
    "    [file_paths]\n",
    "\n",
    "    input_file_path=./test_data.txt\n",
    "    ;output_file_path=./hashed_output.csv\n",
    "\n",
    "    [configuration]\n",
    "    has_header_row=true\n",
    "\n",
    "The \"[file_paths]\" and \"[configuration]\" are for using this program in standalone mode.  We don't need those here, and we are responsible for dealing with IO and file reading.\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make single instance of the HMACHasher for all values.\n",
    "my_hasher = HMACHasher()\n",
    "\n",
    "# load the passphrase/salt from the configuration file\n",
    "hmac_hasher_ini_file_path = configuration_directory + \"/hashing_configuration.ini\"\n",
    "\n",
    "# store configuration file path in HMACHasher, then load config.\n",
    "my_hasher.configuration_ini_file_path = hmac_hasher_ini_file_path\n",
    "config_load_messages = my_hasher.load_configuration_from_ini_file()\n",
    "\n",
    "# errors?\n",
    "if ( len( config_load_messages ) > 0 ):\n",
    "\n",
    "    # errors.\n",
    "    for error_message in config_load_messages:\n",
    "        \n",
    "        print( \"- \" + str( error_message ) )\n",
    "        \n",
    "    #-- END loop over errors. --#\n",
    "\n",
    "else:\n",
    "    \n",
    "    print( \"Config loaded from path \" + str( hmac_hasher_ini_file_path ) + \" at \" + str( datetime.datetime.now() ) )\n",
    "    \n",
    "#-- END check for errors loading configuration. --#\n",
    "\n",
    "print( \"HMACHasher instance created at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test hashing a value.\n",
    "expected_value = \"\"\n",
    "\n",
    "# On first run, this will not match.  To test:\n",
    "# - Copy value from first run into expected_value, above.\n",
    "# - stop kernel and clear output.\n",
    "# - run all cells again.\n",
    "\n",
    "test_value = \"Exculpatory\"\n",
    "test_hash = \"\"\n",
    "test_hash = my_hasher.hash_value( test_value )\n",
    "print( \"FROM \" + str( test_value ) + \" TO \" + str( test_hash ) )\n",
    "print( \"Equal to expected?: \" + str( expected_value == test_hash ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Functions\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions - hash functions\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Here, we set up a function per type of value.  If you had multiple secrets used within a given file, each function could default to a different hasher.  Here, we default all to the same since we are using a single secret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_ssn( value_IN, hasher_IN = my_hasher ):\n",
    "    \n",
    "    # return reference\n",
    "    hash_OUT = \"\"\n",
    "    \n",
    "    # hash using SSN method:\n",
    "    # - removes punctuation\n",
    "    # - replaces multiple spaces with a single space\n",
    "    # - strips white space from ends\n",
    "    hash_OUT = hasher_IN.hash_ssn_value( value_IN )\n",
    "    \n",
    "    return hash_OUT\n",
    "\n",
    "#-- END function hash_ssn() --#\n",
    "\n",
    "print( \"Function hash_ssn() declared at \" + str( datetime.datetime.now() ) )\n",
    "\n",
    "    \n",
    "def hash_name( value_IN, hasher_IN = my_hasher ):\n",
    "    \n",
    "    # return reference\n",
    "    hash_OUT = \"\" \n",
    "     \n",
    "    # hash using name method to standardize:\n",
    "    # - converts to upper case\n",
    "    # - removes punctuation\n",
    "    # - replaces multiple spaces with a single space\n",
    "    # - strips white space from ends\n",
    "    hash_OUT = hasher_IN.hash_name_value( value_IN )\n",
    "    \n",
    "    return hash_OUT\n",
    "\n",
    "#-- END function hash_name() --#\n",
    "\n",
    "print( \"Function hash_name() declared at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hash data\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function parse_fixed_width_record\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fixed_width_record( record_string_IN, fixed_width_spec_list_IN ):\n",
    "    \n",
    "    '''\n",
    "    Accepts fixed-width file line string and list of field spec dictionaries of fields to be extracted.\n",
    "    For each, in the order they appear in the list, extracts field from record string and\n",
    "        appends it to output list.  Returns list of values.\n",
    "    '''\n",
    "    \n",
    "    # CONSTANTS-ish\n",
    "    FIXED_WIDTH_SPEC_NAME = \"name\"\n",
    "    FIXED_WIDTH_SPEC_INDEX = \"index\"\n",
    "    FIXED_WIDTH_SPEC_START = \"start\"\n",
    "    FIXED_WIDTH_SPEC_END = \"end\"\n",
    "\n",
    "    # return reference\n",
    "    value_list_OUT = None\n",
    "    \n",
    "    # declare variables\n",
    "    record_string = \"\"\n",
    "    field_counter = -1\n",
    "    fixed_width_spec_list = []\n",
    "    fixed_width_spec = {}\n",
    "    field_name = None\n",
    "    field_index = None\n",
    "    field_start = None\n",
    "    field_end = None\n",
    "    start_index = -1\n",
    "    end_index = -1\n",
    "    field_value = None\n",
    "\n",
    "    # Make sure there is a value\n",
    "    if ( ( record_string_IN is not None ) and ( record_string_IN != \"\" ) ):\n",
    "        \n",
    "        # record string\n",
    "        record_string = record_string_IN\n",
    "        \n",
    "        print( \"\\n====> record string: {}\".format( record_string ) )\n",
    "        \n",
    "        # init\n",
    "        value_list_OUT = []\n",
    "\n",
    "        # loop over spec\n",
    "        field_counter = 0\n",
    "        fixed_width_spec_list = fixed_width_spec_list_IN\n",
    "        for fixed_width_spec in fixed_width_spec_list:\n",
    "            \n",
    "            # get values\n",
    "            field_name = fixed_width_spec[ FIXED_WIDTH_SPEC_NAME ]\n",
    "            field_index = fixed_width_spec[ FIXED_WIDTH_SPEC_INDEX ]\n",
    "            field_start = fixed_width_spec[ FIXED_WIDTH_SPEC_START ]\n",
    "            field_end = fixed_width_spec[ FIXED_WIDTH_SPEC_END ]\n",
    "            \n",
    "            # convert start and end to 0-indexed slice indices:\n",
    "            start_index = field_start - 1\n",
    "            end_index = field_end\n",
    "            \n",
    "            # get field value\n",
    "            field_value = record_string[ start_index : end_index ]\n",
    "            \n",
    "            # strip white space\n",
    "            field_value = field_value.strip()\n",
    "            \n",
    "            # append to output list.\n",
    "            value_list_OUT.append( field_value )\n",
    "            \n",
    "            # sanity check - in desired index?\n",
    "            print( \"- field {} = {}; index = {}; desired index = {}\".format( field_name, field_value, field_counter, field_index ) )\n",
    "            \n",
    "            # increment counter\n",
    "            field_counter += 1\n",
    "            \n",
    "        #-- END loop over fields. --#\n",
    "\n",
    "    #-- END check to see if string passed in. --#\n",
    "    \n",
    "    return value_list_OUT\n",
    "\n",
    "#-- END function parse_fixed_width_record() --#\n",
    "\n",
    "print( \"Function parse_fixed_width_record() declared at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fixed-width field spec\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define fixed-width field spec list\n",
    "\n",
    "# CONSTANTS-ish\n",
    "FIXED_WIDTH_SPEC_NAME = \"name\"\n",
    "FIXED_WIDTH_SPEC_INDEX = \"index\"\n",
    "FIXED_WIDTH_SPEC_START = \"start\"\n",
    "FIXED_WIDTH_SPEC_END = \"end\"\n",
    "\n",
    "# declare variables\n",
    "field_name = \"\"\n",
    "fixed_width_field_list = []\n",
    "fixed_width_spec = {}\n",
    "\n",
    "# ==> init fixed-width spec.\n",
    "# - Must include all columns we care to extract, in the order we want them to appear in list.\n",
    "\n",
    "# ID, index 0 - 1-9 (so 0-8)\n",
    "field_name = \"ID\"\n",
    "fixed_width_spec = {}\n",
    "fixed_width_spec[ FIXED_WIDTH_SPEC_NAME ] = field_name\n",
    "fixed_width_spec[ FIXED_WIDTH_SPEC_INDEX ] = 0\n",
    "fixed_width_spec[ FIXED_WIDTH_SPEC_START ] = 1\n",
    "fixed_width_spec[ FIXED_WIDTH_SPEC_END ] = 9\n",
    "fixed_width_field_list.append( fixed_width_spec )\n",
    "\n",
    "# first_name, index 1 - 10-24 (so 9-23)\n",
    "field_name = \"first_name\"\n",
    "fixed_width_spec = {}\n",
    "fixed_width_spec[ FIXED_WIDTH_SPEC_NAME ] = field_name\n",
    "fixed_width_spec[ FIXED_WIDTH_SPEC_INDEX ] = 1\n",
    "fixed_width_spec[ FIXED_WIDTH_SPEC_START ] = 10\n",
    "fixed_width_spec[ FIXED_WIDTH_SPEC_END ] = 24\n",
    "fixed_width_field_list.append( fixed_width_spec )\n",
    "\n",
    "# middle_name, index 2 - 25 (so 24)\n",
    "field_name = \"middle_name\"\n",
    "fixed_width_spec = {}\n",
    "fixed_width_spec[ FIXED_WIDTH_SPEC_NAME ] = field_name\n",
    "fixed_width_spec[ FIXED_WIDTH_SPEC_INDEX ] = 2\n",
    "fixed_width_spec[ FIXED_WIDTH_SPEC_START ] = 25\n",
    "fixed_width_spec[ FIXED_WIDTH_SPEC_END ] = 25\n",
    "fixed_width_field_list.append( fixed_width_spec )\n",
    "\n",
    "# last_name, index 3 - 26-45 (so 25-44)\n",
    "field_name = \"last_name\"\n",
    "fixed_width_spec = {}\n",
    "fixed_width_spec[ FIXED_WIDTH_SPEC_NAME ] = field_name\n",
    "fixed_width_spec[ FIXED_WIDTH_SPEC_INDEX ] = 3\n",
    "fixed_width_spec[ FIXED_WIDTH_SPEC_START ] = 26\n",
    "fixed_width_spec[ FIXED_WIDTH_SPEC_END ] = 45\n",
    "fixed_width_field_list.append( fixed_width_spec )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hashing spec\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define simple hash specification - for each column to be hashed:\n",
    "# - index\n",
    "# - hash function to use\n",
    "# - hasher to use\n",
    "\n",
    "# CONSTANTS-ish\n",
    "HASH_SPEC_INDEX = \"index\"\n",
    "HASH_SPEC_HASH_FUNCTION = \"hash_function\"\n",
    "HASH_SPEC_HASHER = \"hasher\"\n",
    "\n",
    "# declare variables\n",
    "hash_spec_list = []\n",
    "hash_spec = {}\n",
    "\n",
    "# ID, index 0 - 1-9 (so 0-8)\n",
    "hash_spec = {}\n",
    "hash_spec[ HASH_SPEC_INDEX ] = 0\n",
    "hash_spec[ HASH_SPEC_HASH_FUNCTION ] = hash_ssn\n",
    "hash_spec[ HASH_SPEC_HASHER ] = my_hasher\n",
    "hash_spec_list.append( hash_spec )\n",
    "\n",
    "# first_name, index 1 - 10-24 (so 9-23)\n",
    "hash_spec = {}\n",
    "hash_spec[ HASH_SPEC_INDEX ] = 1\n",
    "hash_spec[ HASH_SPEC_HASH_FUNCTION ] = hash_name\n",
    "hash_spec[ HASH_SPEC_HASHER ] = my_hasher\n",
    "hash_spec_list.append( hash_spec )\n",
    "\n",
    "# middle_name, index 2 - 25 (so 24)\n",
    "hash_spec = {}\n",
    "hash_spec[ HASH_SPEC_INDEX ] = 2\n",
    "hash_spec[ HASH_SPEC_HASH_FUNCTION ] = hash_name\n",
    "hash_spec[ HASH_SPEC_HASHER ] = my_hasher\n",
    "hash_spec_list.append( hash_spec )\n",
    "\n",
    "# last_name, index 3 - 26-45 (so 25-44)\n",
    "hash_spec = {}\n",
    "hash_spec[ HASH_SPEC_INDEX ] = 3\n",
    "hash_spec[ HASH_SPEC_HASH_FUNCTION ] = hash_name\n",
    "hash_spec[ HASH_SPEC_HASHER ] = my_hasher\n",
    "hash_spec_list.append( hash_spec )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hash!\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ==> example data\n",
    "\n",
    "# declare variables - loop over files\n",
    "file_list = []\n",
    "file_path = \"\"\n",
    "path_part_list = []\n",
    "file_name = \"\"\n",
    "temp_file_name = \"\"\n",
    "file_year = \"\"\n",
    "file_quarter = \"\"\n",
    "\n",
    "# declare variables - process each file\n",
    "path_separator = \"/\"\n",
    "input_file = \"\"\n",
    "input_file_match = \"\"\n",
    "input_file_search_string = \"*.txt\"\n",
    "input_file_encoding = \"utf-8\"\n",
    "has_header_row = False\n",
    "output_file = \"\"\n",
    "line_counter = -1\n",
    "hash_output_file = None\n",
    "to_hash_csv_file = None\n",
    "input_csv_reader = None\n",
    "current_line = None\n",
    "output_csv_writer = None\n",
    "current_record = None\n",
    "\n",
    "# values from record\n",
    "current_value = \"\"\n",
    "hashed_value = \"\"\n",
    "row_value_list = []\n",
    "current_hash_spec = None\n",
    "hash_spec_index = -1\n",
    "hash_spec_hash_function = None\n",
    "hash_spec_hasher = None\n",
    "\n",
    "# first get list of *.csv files in directory.\n",
    "print( \"Looking for files in {}\".format( input_file_directory_path ) )\n",
    "input_file_match = \"{}/{}\".format( input_file_directory_path, input_file_search_string )\n",
    "file_list = glob.glob( input_file_match )\n",
    "print( \"File list: \" + str( file_list ) )\n",
    "\n",
    "for file_path in file_list:\n",
    "    \n",
    "    # Parse out the file name.\n",
    "    path_part_list = file_path.split( path_separator )\n",
    "    file_name = path_part_list[ -1 ]\n",
    "    \n",
    "    print( \"--> Current file: {} @ {}\".format( str( file_name ), str( datetime.datetime.now() ) ) )\n",
    "\n",
    "    # initialize\n",
    "    line_counter = 0\n",
    "    input_file = file_path\n",
    "    output_file = output_file_directory_path + \"/hashed-\" + file_name\n",
    "\n",
    "    # open the output file for writing.\n",
    "    with open( output_file, \"w\" ) as hash_output_file:\n",
    "\n",
    "        # init CSV writer.\n",
    "        output_csv_writer = csv.writer( hash_output_file, delimiter = \",\" )\n",
    "\n",
    "        # open the input file for reading\n",
    "        with open( input_file, encoding = input_file_encoding ) as to_hash_file:\n",
    "\n",
    "            # output header row?\n",
    "            if ( has_header_row == True ):\n",
    "                \n",
    "                # yes - output first row as is.\n",
    "                current_record = to_hash_file.readline()\n",
    "                row_value_list = parse_fixed_width_record( current_record, fixed_width_field_list )\n",
    "                output_csv_writer.writerow( row_value_list )\n",
    "                \n",
    "            #-- END check to see if header row --#\n",
    "\n",
    "            # loop over records\n",
    "            for current_record in to_hash_file:\n",
    "                \n",
    "                # initialize values\n",
    "                current_value = \"\"\n",
    "                hashed_value = \"\"\n",
    "\n",
    "                # initialize output list from input record\n",
    "                row_value_list = parse_fixed_width_record( current_record, fixed_width_field_list )\n",
    "\n",
    "                # increment line counter\n",
    "                line_counter += 1\n",
    "\n",
    "                # loop over hash spec\n",
    "                for current_hash_spec in hash_spec_list:\n",
    "                    \n",
    "                    # read hash spec information\n",
    "                    hash_spec_index = current_hash_spec[ HASH_SPEC_INDEX ]\n",
    "                    hash_spec_hash_function = current_hash_spec[ HASH_SPEC_HASH_FUNCTION ]\n",
    "                    hash_spec_hasher = current_hash_spec[ HASH_SPEC_HASHER ]\n",
    "\n",
    "                    # get value for requested index\n",
    "                    current_value = row_value_list[ hash_spec_index ]\n",
    "                    \n",
    "                    # hash it.\n",
    "                    hashed_value = hash_spec_hash_function( current_value, hash_spec_hasher )\n",
    "                    \n",
    "                    # place hashed value in row value list.\n",
    "                    row_value_list[ hash_spec_index ] = hashed_value\n",
    "                    \n",
    "                #-- END loop over hash spec list. --#\n",
    "                    \n",
    "                # write to output file.\n",
    "                output_csv_writer.writerow( row_value_list )\n",
    "\n",
    "                if ( ( line_counter % 100000 ) == 0 ):\n",
    "                    print( \"- Hashed \" + str( line_counter ) + \" lines at \" + str( datetime.datetime.now() ) )\n",
    "                #-- END check to see if we've done 1000 records. --#\n",
    "\n",
    "            #-- END loop over input lines.\n",
    "\n",
    "        #-- END with ... to_hash_csv_file --#\n",
    "\n",
    "    #-- END with ... hash_output_file --#    \n",
    "\n",
    "#-- END loop over file list --#\n",
    "\n",
    "print( \"All files processed at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluate\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Once the cell above has completed, you should now in your output folder (by default, the same directory as this notebook) have an output file named `hashed-<input_file_name>` per input file."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
